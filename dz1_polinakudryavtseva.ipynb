{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dz1-polinakudryavtseva.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx7qsG1HNByIFeZ0N/u/8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PolinaKudryavtseva/third-year-homeworks/blob/main/dz1_polinakudryavtseva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VzfTBZ6RW25"
      },
      "source": [
        "**Домашнее задание 1. Работа Полины Кудрявцевой**\n",
        "\n",
        "Краулер собирает отзывы с сайта afisha.ru, из раздела про драматические театральные постановки. Отзывы там поделены на положительные и отрицательные, эта программа обкачивает каждый раздел по отдельности. Положительных и отрицательных комментариев собрано по 50, тестовые отзывы собираются отдельно.\n",
        "\n",
        "Библиотеки импортируются по необходимости."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfzjshz3vYjr"
      },
      "source": [
        "import requests\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "session = requests.session()\n",
        "\n",
        "for _ in range(5):\n",
        "    response = session.get('https://www.afisha.ru/msk/schedule_theatre/drama_plays/').text\n",
        "    time.sleep(3)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_mhSId_zykB"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "soup = BeautifulSoup(response,'html.parser')\n",
        "positive_links = []\n",
        "negative_links = []\n",
        "\n",
        "#на главной страницы раздела про драматические постановки собираем страницы каждого спектакля,\n",
        "#добавляем к ним часть адреса на положительные/отрицательные отзывы\n",
        "\n",
        "plays = soup.find_all('h3')\n",
        "for play in plays:\n",
        "  link = re.search('/performance/\\d*/', str(play))\n",
        "  positive_link = 'https://www.afisha.ru' + str(link.group()) + 'reviews/positive/'\n",
        "  positive_links.append(positive_link)\n",
        "  negative_link = 'https://www.afisha.ru' + str(link.group()) + 'reviews/negative/'\n",
        "  negative_links.append(negative_link)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmP5k6l0n9yA"
      },
      "source": [
        "positive_texts = [] #здесь будут лежать необработанные тексты положительных отзывов\n",
        "while len(positive_texts) <= 50:\n",
        "  for link in positive_links:\n",
        "    response = session.get(link).text\n",
        "    time.sleep(2)\n",
        "    soup = BeautifulSoup(response,'html.parser')\n",
        "    texts = soup.find_all('div', {'class':'restrict-text review__text'})\n",
        "    for i in texts:\n",
        "      text = i.find('p')\n",
        "      positive_texts.append(text)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMg6MzCO6IPM"
      },
      "source": [
        "negative_texts = [] #здесь будут лежать необработанные тексты отрицательных отзывов\n",
        "while len(negative_texts) <= 50:\n",
        "  for link in negative_links:\n",
        "    response = session.get(link).text\n",
        "    time.sleep(2)\n",
        "    soup = BeautifulSoup(response,'html.parser')\n",
        "    texts = soup.find_all('div', {'class':'restrict-text review__text'})\n",
        "    for i in texts:\n",
        "      text = i.find('p')\n",
        "      negative_texts.append(text)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VJ-73OeHaBy"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGhEQD93W6uv"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz3RWNCjTlKd"
      },
      "source": [
        "Тексты по отдельности положительных и отрицательных отзывов приводятся к нижнему регистру и лемматизируются, затем приводятся к начальной форме."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ud0LViHyeQ"
      },
      "source": [
        "positive_lemmas = []\n",
        "for text in positive_texts:\n",
        "  text = str(text)\n",
        "  text = re.sub('<\\w+>', '', text)\n",
        "  text = re.sub('<//\\w+>', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  positive_tokens = [w for w in tokens if w.isalpha()]\n",
        "  for word in positive_tokens:\n",
        "      analise = morph.parse(word)\n",
        "      one = analise[0]\n",
        "      form = one.normal_form\n",
        "      positive_lemmas.append(form)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91-lHXDZkWgS"
      },
      "source": [
        "negative_lemmas = []\n",
        "for text in negative_texts:\n",
        "  text = str(text)\n",
        "  text = re.sub('<\\w+>', '', text)\n",
        "  text = re.sub('<//\\w+>', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  negative_tokens = [w for w in tokens if w.isalpha()]\n",
        "  for word in negative_tokens:\n",
        "      analise = morph.parse(word)\n",
        "      one = analise[0]\n",
        "      form = one.normal_form\n",
        "      negative_lemmas.append(form)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VggiFgKVsFhP"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLaTMFG2ru1J"
      },
      "source": [
        "positive_freqlist = Counter() #здесь будут словари частотностей уникальных (тех, которые есть только в таких отзывах) слов положительных отзывов\n",
        "negative_freqlist = Counter() #здесь будут словари частотностей уникальных слов отрицательных отзывов\n",
        "\n",
        "for word in positive_lemmas:\n",
        "  if word not in negative_lemmas:\n",
        "    positive_freqlist[word] += 1\n",
        "for word in negative_lemmas:\n",
        "  if word not in positive_lemmas:\n",
        "    negative_freqlist[word] += 1\n",
        "\n",
        "positive_dictionary = dict(positive_freqlist)\n",
        "negative_dictionary = dict(negative_freqlist)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4aNsi2nIeUQ"
      },
      "source": [
        "test_positive_texts = [] #здесь идет работа с тестовой подборкой положительных отзывов\n",
        "response = session.get('https://www.afisha.ru/performance/83857/reviews/positive/').text\n",
        "soup = BeautifulSoup(response,'html.parser')\n",
        "texts = soup.find_all('div', {'class':'restrict-text review__text'})\n",
        "for i in texts:\n",
        "  text = i.find('p')\n",
        "  test_positive_texts.append(text)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oDggJwRJNyE"
      },
      "source": [
        "test_positive_lemmas_list = []\n",
        "for text in test_positive_texts:\n",
        "  text = str(text)\n",
        "  text = re.sub('<\\w+>', '', text)\n",
        "  text = re.sub('<//\\w+>', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  test_positive_tokens = [w for w in tokens if w.isalpha()]\n",
        "  test_positive_lemmas = []\n",
        "  for word in test_positive_tokens:\n",
        "      analise = morph.parse(word)\n",
        "      one = analise[0]\n",
        "      form = one.normal_form\n",
        "      test_positive_lemmas.append(form)\n",
        "  test_positive_lemmas_list.append(test_positive_lemmas)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4TifqfpxiTs"
      },
      "source": [
        "test_negative_texts = [] #здесь идет работа с тестовой подборкой отрицательных отзывов\n",
        "response = session.get('https://www.afisha.ru/performance/86394/reviews/negative/').text\n",
        "soup = BeautifulSoup(response,'html.parser')\n",
        "texts = soup.find_all('div', {'class':'restrict-text review__text'})\n",
        "for i in texts:\n",
        "  text = i.find('p')\n",
        "  test_negative_texts.append(text)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx1j_ngbPRUy"
      },
      "source": [
        "test_negative_lemmas_list = []\n",
        "for text in test_negative_texts:\n",
        "  text = str(text)\n",
        "  text = re.sub('<\\w+>', '', text)\n",
        "  text = re.sub('<//\\w+>', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  test_negative_tokens = [w for w in tokens if w.isalpha()]\n",
        "  test_negative_lemmas = []\n",
        "  for word in test_negative_tokens:\n",
        "      analise = morph.parse(word)\n",
        "      one = analise[0]\n",
        "      form = one.normal_form\n",
        "      test_negative_lemmas.append(form)\n",
        "  test_negative_lemmas_list.append(test_negative_lemmas)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7VgRP6IU1ke"
      },
      "source": [
        "Следующая функция делает предположение, к какому виду отзывов относится предлагаемый текст. Потом считается accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpj_eOa_Ay1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWpAvFCr9LlM"
      },
      "source": [
        "def review_detect(positive_dictionary, negative_dictionary, test_lemmas, test_negative_lemmas, test_positive_lemmas):\n",
        "\n",
        "  positiveness = 0\n",
        "  negativeness = 0\n",
        "\n",
        "  answers = []\n",
        "  original = []\n",
        "\n",
        "  for text in test_lemmas:\n",
        "    if text in test_positive_lemmas:\n",
        "      original.append('positive')\n",
        "    if text in test_negative_lemmas:\n",
        "      original.append('negative')\n",
        "\n",
        "    for lemma in text:\n",
        "      if lemma in positive_dictionary.keys():\n",
        "        positiveness += 1\n",
        "      if lemma in negative_dictionary.keys():\n",
        "        negativeness += 1\n",
        "    if positiveness >= negativeness:\n",
        "      answers.append('positive')\n",
        "    else:\n",
        "      answers.append('negative')\n",
        "\n",
        "  accuracy = print(\"Accuracy: %.4f\" % accuracy_score(answers, original))\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3WXbKP1bz9",
        "outputId": "33ae8a47-d87b-481e-a8bb-c2cc64bc675b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Проверим, что скажет функция про позитивный комментарий.')\n",
        "review_detect(positive_dictionary, negative_dictionary, test_positive_lemmas_list, test_negative_lemmas_list, test_positive_lemmas_list)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Проверим, что скажет функция про позитивный комментарий.\n",
            "Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07i2W6ynQLM3",
        "outputId": "897fa220-42d6-465c-fbb8-fe9eaba027a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Проверим, что скажет функция про негативный комментарий.')\n",
        "review_detect(positive_dictionary, negative_dictionary, test_negative_lemmas_list, test_negative_lemmas_list, test_positive_lemmas_list)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Проверим, что скажет функция про негативный комментарий.\n",
            "Accuracy: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyR4jTlUVCG1"
      },
      "source": [
        "Предложения:\n",
        "- accuracy будет намного выше, если сделать подборку больше. Такой краулер будет работать дольше, но слов в словарях получится больше и вероятность правильного предсказания повысится\n",
        "- можно было бы добавить сюда что-то вроде словаря синонимов, или word2vec, чтобы если в отзыве нет конкретного слова, но есть близкое к слову из словаря по значению, этот отзыв имел более правильное предсказание."
      ]
    }
  ]
}